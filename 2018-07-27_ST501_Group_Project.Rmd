---
title: "ST501 Group Project"
author: "Our Group"
date: "7/20/2018"
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

# Introduction

# Part 1 Convergences

## A

$$f_Y(y) = \frac{1}{2b}e^{-(\frac{|y-\mu|}{b})}$$

Given: $\mu = 0$ and $b=5$

$$E(Y) = \int_{-\infty}^{\infty} y * f(y)dy$$
$$= \int_{-\infty}^0y*\frac{1}{10}e^{\frac{y}{5}} + \int^{\infty}_0y*\frac{1}{10}e^{\frac{-y}{5}}$$

$$= \frac{1}{10}\Bigg[\int_{-\infty}^0ye^{\frac{y}{5}} + \int^{\infty}_0y*e^{\frac{-y}{5}}\Bigg]$$

$$= \frac{1}{10}\Bigg[\Big[(5y-25)e^{\frac{y}{5}}\Big]_{-\infty}^0 + \Big[(-5y-25)e^{\frac{-y}{5}}\Big]_0^\infty\Bigg]$$
$$=\frac{1}{10}\Big[-25+25\Big]$$
$$E(Y) = 0 \text{   }\blacksquare$$
$$E(Y^2) = \int_{-\infty}^{\infty} y^2 * f(y)dy$$

$$= \frac{1}{10}\Bigg[\int_{-\infty}^0y^2e^{\frac{y}{5}} + \int^{\infty}_0y^2*e^{\frac{-y}{5}}\Bigg]$$
$$= \frac{1}{10}*\Big[250+250\Big]$$

$$E(Y^2)= 50 \ \ \blacksquare$$

Therefor $E(Y^2)$ exists.

Thus:

$E(Y) = 0$, $E(Y^2) = 50$ then $Var(Y) = 50$ by the variance computing formula.

$$L = \frac{1}{n}\sum_{i=1}^{n}Y_i^2$$
By the Law of Large Numbers:

$$\frac{1}{n}\sum_{i=1}^{n}Y_i\ \ \underrightarrow{p} \ E(Y_i)$$
By generalisation of the Law of Large Numbers:

$$L = \frac{1}{n}\sum_{i=1}^{n}Y_i^2 \ \ \underrightarrow{p} \ E(Y_i^2) = 50$$
Therefore:

$$L \ \ \underrightarrow{p} \ \ 50 \ \ \blacksquare$$

## B

By the continuity theorem, $K = \sqrt{L} \ \ \underrightarrow{p} \ \sqrt{50}$

Thus: $K\ \ \underrightarrow{p} \ \sqrt{50}$.

## C
Derrive the CDF of the double exponential distribution.

$$f_Y(y) = \frac{1}{2b} * e^{-(\frac{|{y-\mu|)}}{b})}$$

This yields two cases for the CDF:

$$
F_Y(y)=
\begin{cases}
\int_{-\infty}^tf_Y(Y)dt & \text{for } y \le \mu \\
\int^{\infty}_tf_Y(Y)dt & \text{for } y \ge \mu \\
\end{cases}
$$

Solving for these leaves us with the following:

For $y \le \mu$ :

$$\int_{-\infty}^yf_Y(Y)dt$$
$$\int_{-\infty}^y\frac{1}{2b} * e^{-(\frac{{t-\mu}}{b})}dt$$
We know that in this case we are solving for when the exponent is positive.

$$\int_{-\infty}^y\frac{1}{2b} * e^{(\frac{|{t-\mu|)}}{b})}dt$$

$$\frac{1}{2b} * e^{(\frac{t-\mu}{b})}*b|_{-\infty}^{y}=\frac{1}{2}e^{(\frac{t-\mu}{b})} - 0 = \frac{1}{2}e^{(\frac{t-\mu}{b})}$$

For the case where $y \ge \mu$

$$\int_{-\infty}^yf_Y(Y)dt$$

$$\int_{-\infty}^y\frac{1}{2b} * e^{-(\frac{{t-\mu}}{b})}dt$$

This must be further split into:

$$\int_{-\infty}^\mu\frac{1}{2b} * e^{-(\frac{{t-\mu}}{b})}dt + \int_{\mu}^y\frac{1}{2b} * e^{-(\frac{{t-\mu}}{b})}dt$$

$$\frac{1}{2b} * e^{(\frac{-t+\mu}{b})}*-b|_{-\infty}^{\mu} + \frac{1}{2b} * e^{(\frac{-t+\mu}{b})}*-b|_{\mu}^{y}$$

$$\frac{1}{2} - \frac{1}{2}e^{\frac{\mu-y}{b}} + \frac{1}{2}$$

Thus for this case:

$$1-\frac{1}{2}e^{\frac{\mu-y}{b}}$$

In conclusion the CDF for the double exponential distribution is:

$$F_Y(y)=
\begin{cases}
\frac{1}{2}e^{(\frac{y-\mu}{b})} & \text{for } y \le \mu \\
1-\frac{1}{2}e^{\frac{\mu-y}{b}} & \text{for } y \ge \mu
\end{cases}$$

## D and E


First to generate these random values we need to create the inverse functions.

For the case when:

$$x\lt\mu$$

$$u = \frac{1}{2}e^{\frac{y-\mu}{b}}$$

$$b*log(2u) = x - \mu$$

Thus 
$$x = \mu + b*log(2u)$$ 


for 
$$u>0$$

$$x\lt\mu$$

For the case when 

$$x \ge \mu$$

$$u = 1 - \frac{1}{2}e^{-\frac{y-\mu}{b}}$$
$$-b*log(2-2u) = y- \mu$$

Thus 
$$\mu-b*log(2-2u) = y$$

For u<1, x >= mu

Using these inverse functions we can now do simulations.

```{r}

set.seed(336)

test_func<-function(u){
  out_come_1 <- 0 + 5*log(2*u)
  out_come_2 <- 0 - 5*log(2-2*u)
  cbind(out_come_1^2, out_come_2^2)
}

a<-(test_func(seq(0.01,.999,.001)))

rdoublex <- function(u, mu = 0, b = 5){
  if( u < 0.5){
    out_come_1 <- mu + b*log(2*u)
    out_come_1
  } else{
     out_come_2 <- mu - b*log(2-2*u)
     out_come_2
  }
    
}


output_matrix <- matrix(0, nrow= 250, ncol = 50)

# Basic Function
for( j in 1:50){
  for(i in 1:250){
    random_value <- runif(i, 0, 1)
    output_matrix[i, j]<- mean(vapply(random_value, FUN = rdoublex, double(1)))
  }
}

p1 <- output_matrix %>% 
  as.data.frame() %>% 
  mutate(N = 1:250) %>% 
  gather(replication, value, -N) %>% 
  ggplot(aes(N, value))+
  geom_point(alpha=1/5)+
  theme_minimal()+
  labs(
    title = "Convergence of a Laplace Distribution with mu = 0, b = 5",
    subtitle = "50 Samples Drawn per Sample Size, N",
    x = "Sample Size, N"
  )

#L

output_matrix <- matrix(0, nrow= 250, ncol = 50)

# Basic Function
for( j in 1:50){
  for(i in 1:250){
    random_value <- runif(i, 0, 1)
    output_matrix[i, j]<- mean(vapply(random_value, FUN = rdoublex, double(1))^2)
  }
}

limit_one <- 20
p2 <- output_matrix %>% 
  as.data.frame() %>% 
  mutate(N = 1:250) %>% 
  gather(replication, value, -N) %>% 
  ggplot(aes(N, value))+
  geom_point(alpha=1/5)+
  theme_minimal()+
  labs(
    title = "Convergence of a Laplace Distribution of Y_i^{2} with ~mu~= 0, b = 5",
    subtitle = "50 Samples Drawn per Sample Size, N",
    x = "Sample Size, N"
  )+
  geom_hline(yintercept = 50, size = 1, color = "blue")+
  geom_hline(yintercept = 50 + limit_one, linetype = "dotted", color = "red", size = 1)+
  geom_hline(yintercept = 50 - limit_one, linetype = "dotted", color = "red", size = 1)
p2
#K

output_matrix <- matrix(0, nrow= 250, ncol = 50)

# Basic Function
for( j in 1:50){
  for(i in 1:250){
    random_value <- runif(i, 0, 1)
    output_matrix[i, j]<- sqrt(mean(vapply(random_value, FUN = rdoublex, double(1))^2))
  }
}

limit_two <- 3
p3 <- output_matrix %>% 
  as.data.frame() %>% 
  mutate(N = 1:250) %>% 
  gather(replication, value, -N) %>% 
  ggplot(aes(N, value))+
  geom_point(alpha=1/5)+
  theme_minimal()+
  labs(
    title = "Convergence of a Laplace Distribution of sqrt(Y_i^{2}) with mu= 0, b = 5",
    subtitle = "50 Samples Drawn per Sample Size, N",
    x = "Sample Size, N"
  )+
  geom_hline(yintercept = 7.07, size = 1, color = "blue")+
  geom_hline(yintercept = 7.07 + limit_two, linetype = "dotted", color = "red", size = 1)+
  geom_hline(yintercept = 7.07 - limit_two, linetype = "dotted", color = "red", size = 1)
p3
```

These plots show that as the sample size increases the values we see approach the expected values. This is graphically showing the convergence of these functions to their expected values as the sample size increases. 